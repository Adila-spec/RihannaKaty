{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce2bb89",
   "metadata": {},
   "source": [
    "# ADS 509 Assignment 5.1: Topic Modeling\n",
    "\n",
    "This notebook holds Assignment 5.1 for Module 5 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In this assignment you will work with a categorical corpus that accompanies `nltk`. You will build the three types of topic models described in Chapter 8 of _Blueprints for Text Analytics using Python_: NMF, LSA, and LDA. You will compare these models to the true categories. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87e2c06",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85bce08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:29: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
      "  from tensorflow.python.lib.core import _pywrap_bfloat16\n",
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:511: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object,\n",
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:553: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object,\n",
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:563: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool,\n",
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:176: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object: SlowAppendObjectArrayToTensorProto,\n",
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:177: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool: SlowAppendBoolArrayToTensorProto,\n",
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\tensorflow\\python\\ops\\numpy_ops\\np_random.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def randint(low, high=None, size=None, dtype=onp.int):  # pylint: disable=missing-function-docstring\n",
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:569: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  (np.object, string),\n",
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:570: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  (np.bool, bool),\n",
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:594: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_STRING: np.object,\n",
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:598: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_BOOL: np.bool,\n",
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:615: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_STRING_REF: np.object,\n",
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:620: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_BOOL_REF: np.bool,\n",
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\tensorboard\\util\\tensor_util.py:109: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object: SlowAppendObjectArrayToTensorProto,\n",
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\tensorboard\\util\\tensor_util.py:110: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool: SlowAppendBoolArrayToTensorProto,\n"
     ]
    }
   ],
   "source": [
    "# These libraries may be useful to you\n",
    "\n",
    "from nltk.corpus import brown\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#import gensim\n",
    "#import gensim.corpora as corpora\n",
    "#from gensim.utils import simple_preprocess\n",
    "#from gensim.models import CoherenceModel,LdaMulticore, Phrases \n",
    "#from gensim.models.phrases import Phraser \n",
    "#from gensim.corpora import Dictionary\n",
    "\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5a34d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a218df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add any additional libaries you need here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "494de237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function comes from the BTAP repo.\n",
    "\n",
    "def display_topics(model, features, no_top_words=5):\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1] # invert sort order\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\"  %s (%2.2f)\" % (features[largest[i]], abs(words[largest[i]]*100.0/total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a901c",
   "metadata": {},
   "source": [
    "## Getting to Know the Brown Corpus\n",
    "\n",
    "Let's spend a bit of time getting to know what's in the Brown corpus, our NLTK example of an \"overlapping\" corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "457c59ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For adventure we have 29 articles.\n",
      "For belles_lettres we have 75 articles.\n",
      "For editorial we have 27 articles.\n",
      "For fiction we have 29 articles.\n",
      "For government we have 30 articles.\n",
      "For hobbies we have 36 articles.\n",
      "For humor we have 9 articles.\n",
      "For learned we have 80 articles.\n",
      "For lore we have 48 articles.\n",
      "For mystery we have 24 articles.\n",
      "For news we have 44 articles.\n",
      "For religion we have 17 articles.\n",
      "For reviews we have 17 articles.\n",
      "For romance we have 29 articles.\n",
      "For science_fiction we have 6 articles.\n"
     ]
    }
   ],
   "source": [
    "# categories of articles in Brown corpus\n",
    "for category in brown.categories() :\n",
    "    print(f\"For {category} we have {len(brown.fileids(categories=category))} articles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fb133c",
   "metadata": {},
   "source": [
    "Let's create a dataframe of the articles in of hobbies, editorial, government, news, and romance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f50b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['editorial','government','news','romance','hobbies'] \n",
    "\n",
    "category_list = []\n",
    "file_ids = []\n",
    "texts = []\n",
    "\n",
    "for category in categories : \n",
    "    for file_id in brown.fileids(categories=category) :\n",
    "        \n",
    "        # build some lists for a dataframe\n",
    "        category_list.append(category)\n",
    "        file_ids.append(file_id)\n",
    "        \n",
    "        text = brown.words(fileids=file_id)\n",
    "        texts.append(\" \".join(text))\n",
    "\n",
    "        \n",
    "        \n",
    "df = pd.DataFrame()\n",
    "df['category'] = category_list\n",
    "df['id'] = file_ids\n",
    "df['text'] = texts \n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586f47de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add some helpful columns on the df\n",
    "df['char_len'] = df['text'].apply(len)\n",
    "df['word_len'] = df['text'].apply(lambda x: len(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2128fd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='category'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df.groupby('category').agg({'word_len': 'mean'}).plot.bar(figsize=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554ffeb5",
   "metadata": {},
   "source": [
    "Now do our TF-IDF and Count vectorizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21a7d247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(166, 4941)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_text_vectorizer = CountVectorizer(stop_words=stopwords, min_df=5, max_df=0.7)\n",
    "count_text_vectors = count_text_vectorizer.fit_transform(df[\"text\"])\n",
    "count_text_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "875deba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 4941)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_text_vectorizer = TfidfVectorizer(stop_words=stopwords, min_df=5, max_df=0.7)\n",
    "tfidf_text_vectors = tfidf_text_vectorizer.fit_transform(df['text'])\n",
    "tfidf_text_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e166754f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1062b21",
   "metadata": {},
   "source": [
    "Q: What do the two data frames `count_text_vectors` and `tfidf_text_vectors` hold? \n",
    "\n",
    "A: `count_text_vectors` contains a matrix where the rows represent documents and columns represent unique words among all documents, the values are the number of times each word showing up in each documents. Similar for `tfidf_text_vectors` where the values shows the tfidf score for each document and each word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77c3f94",
   "metadata": {},
   "source": [
    "## Fitting a Non-Negative Matrix Factorization Model\n",
    "\n",
    "In this section the code to fit a five-topic NMF model has already been written. This code comes directly from the [BTAP repo](https://github.com/blueprints-for-text-analytics-python/blueprints-text), which will help you tremendously in the coming sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d28745a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sheri\\anaconda3\\anaconda_64\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    }
   ],
   "source": [
    "nmf_text_model = NMF(n_components=5, random_state=314)\n",
    "W_text_matrix = nmf_text_model.fit_transform(tfidf_text_vectors)\n",
    "H_text_matrix = nmf_text_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a67185e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  mr (0.51)\n",
      "  president (0.45)\n",
      "  kennedy (0.43)\n",
      "  united (0.42)\n",
      "  khrushchev (0.40)\n",
      "\n",
      "Topic 01\n",
      "  said (0.88)\n",
      "  didn (0.46)\n",
      "  ll (0.45)\n",
      "  thought (0.42)\n",
      "  man (0.37)\n",
      "\n",
      "Topic 02\n",
      "  state (0.40)\n",
      "  development (0.36)\n",
      "  tax (0.33)\n",
      "  sales (0.30)\n",
      "  program (0.25)\n",
      "\n",
      "Topic 03\n",
      "  mrs (2.61)\n",
      "  mr (0.78)\n",
      "  said (0.64)\n",
      "  miss (0.52)\n",
      "  car (0.51)\n",
      "\n",
      "Topic 04\n",
      "  game (1.01)\n",
      "  league (0.74)\n",
      "  ball (0.72)\n",
      "  baseball (0.71)\n",
      "  team (0.66)\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf_text_model, tfidf_text_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee51e9b",
   "metadata": {},
   "source": [
    "Now some work for you to do. Compare the NMF factorization to the original categories from the Brown Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c8c8eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>category</th>\n",
       "      <th>editorial</th>\n",
       "      <th>government</th>\n",
       "      <th>hobbies</th>\n",
       "      <th>news</th>\n",
       "      <th>romance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "category  editorial  government  hobbies  news  romance\n",
       "topic                                                  \n",
       "0                20           4        0     8        0\n",
       "1                 4           0        8     0       29\n",
       "2                 2          26       26    11        0\n",
       "3                 0           0        1    17        0\n",
       "4                 1           0        1     8        0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df['topic'] = W_text_matrix.argmax(1)\n",
    "pd.crosstab(df['topic'], df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d4e2bc",
   "metadata": {},
   "source": [
    "Q: How does your five-topic NMF model compare to the original Brown categories? \n",
    "\n",
    "A: Some of the topics are aligned with the correspoding category. For example, topic 2 is about tax and state development which has goverment category. Topic 0 is also mostly about editoral dicussions. Topic 1 covers most of the romance category documents, however, from the top words it is difficult to find relationsip with the category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e37cb5",
   "metadata": {},
   "source": [
    "## Fitting an LSA Model\n",
    "\n",
    "In this section, follow the example from the repository and fit an LSA model (called a \"TruncatedSVD\" in `sklearn`). Again fit a five-topic model and compare it to the actual categories in the Brown corpus. Use the TF-IDF vectors for your fit, as above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da82670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00b53d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "lsa_model  = TruncatedSVD(n_components=5, n_iter=20, random_state=123)\n",
    "lsa_top = lsa_model.fit_transform(tfidf_text_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d94d56f",
   "metadata": {},
   "source": [
    "Q: How does your five-topic LSA model compare to the original Brown categories? \n",
    "\n",
    "A: <!-- Your answer here --> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "377a886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  said (0.44)\n",
      "  mr (0.25)\n",
      "  mrs (0.22)\n",
      "  state (0.20)\n",
      "  man (0.17)\n",
      "\n",
      "Topic 01\n",
      "  said (3.89)\n",
      "  ll (2.73)\n",
      "  didn (2.63)\n",
      "  thought (2.20)\n",
      "  got (1.97)\n",
      "\n",
      "Topic 02\n",
      "  mrs (3.14)\n",
      "  mr (1.73)\n",
      "  said (1.04)\n",
      "  kennedy (0.81)\n",
      "  laos (0.77)\n",
      "\n",
      "Topic 03\n",
      "  mrs (29.33)\n",
      "  club (6.53)\n",
      "  game (6.09)\n",
      "  jr (5.59)\n",
      "  dallas (5.27)\n",
      "\n",
      "Topic 04\n",
      "  game (4.39)\n",
      "  league (3.16)\n",
      "  baseball (3.13)\n",
      "  ball (2.98)\n",
      "  team (2.86)\n"
     ]
    }
   ],
   "source": [
    "# call display_topics on your model\n",
    "display_topics(lsa_model, tfidf_text_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afb9c24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>category</th>\n",
       "      <th>editorial</th>\n",
       "      <th>government</th>\n",
       "      <th>hobbies</th>\n",
       "      <th>news</th>\n",
       "      <th>romance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "category  editorial  government  hobbies  news  romance\n",
       "topic                                                  \n",
       "0                27          30       36    34       21\n",
       "1                 0           0        0     0        8\n",
       "3                 0           0        0     3        0\n",
       "4                 0           0        0     7        0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df['topic'] = lsa_top.argmax(1)\n",
    "pd.crosstab(df['topic'], df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b280a",
   "metadata": {},
   "source": [
    "Q: What is your interpretation of the display topics output? \n",
    "\n",
    "A: From the results, it shows that the topics extracted by LSA do not have much correlation with the original category. Basically, the cross table shows that topic 0 covers all categories, and other topics do not have large enough support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab4d29",
   "metadata": {},
   "source": [
    "## Fitting an LDA Model\n",
    "\n",
    "Finally, fit a five-topic LDA model using the count vectors (`count_text_vectors` from above). Display the results using `pyLDAvis.display` and describe what you learn from that visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "802cb8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit your LDA model here\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda_text_model = LatentDirichletAllocation(n_components=5, random_state=123)\n",
    "lda_top = lda_text_model.fit_transform(count_text_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab18adf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  state (0.94)\n",
      "  use (0.60)\n",
      "  000 (0.47)\n",
      "  small (0.46)\n",
      "  system (0.42)\n",
      "\n",
      "Topic 01\n",
      "  said (1.56)\n",
      "  mrs (0.66)\n",
      "  man (0.49)\n",
      "  mr (0.45)\n",
      "  old (0.43)\n",
      "\n",
      "Topic 02\n",
      "  world (0.63)\n",
      "  mr (0.63)\n",
      "  brown (0.60)\n",
      "  west (0.57)\n",
      "  khrushchev (0.55)\n",
      "\n",
      "Topic 03\n",
      "  states (0.91)\n",
      "  government (0.79)\n",
      "  state (0.77)\n",
      "  united (0.76)\n",
      "  president (0.66)\n",
      "\n",
      "Topic 04\n",
      "  feed (0.51)\n",
      "  american (0.51)\n",
      "  peace (0.48)\n",
      "  day (0.47)\n",
      "  corps (0.38)\n"
     ]
    }
   ],
   "source": [
    "# Call `display_topics` on your fitted model here\n",
    "display_topics(lda_text_model, count_text_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12057bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>category</th>\n",
       "      <th>editorial</th>\n",
       "      <th>government</th>\n",
       "      <th>hobbies</th>\n",
       "      <th>news</th>\n",
       "      <th>romance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "category  editorial  government  hobbies  news  romance\n",
       "topic                                                  \n",
       "0                 2           6       11     4        0\n",
       "1                11           0        9    27       29\n",
       "2                 4           2        7     0        0\n",
       "3                 5          18        0    10        0\n",
       "4                 5           4        9     3        0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['topic'] = lda_top.argmax(1)\n",
    "pd.crosstab(df['topic'], df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c67876",
   "metadata": {},
   "source": [
    "Q: What inference do you draw from the displayed topics for your LDA model? \n",
    "\n",
    "A: As showns in the chart, each topic is using specific set of words. Topic 3 mostly covers goverment related documents. Topic 2 mostly contains hobbies related words. \n",
    "\n",
    "\n",
    "Q: How does your five-topic LDA model compare to the original Brown categories? \n",
    "\n",
    "A: LDA topics are closer to original categories, for example topic 3 covers mostly categories goverment and news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6aae75ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_display = pyLDAvis.sklearn.prepare(lda_text_model, count_text_vectors, count_text_vectorizer, sort_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a89fc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1786427936320368967507433283\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1786427936320368967507433283_data = {\"mdsDat\": {\"x\": [-0.038768960863230055, 0.19622933427950154, 0.03799953433897467, -0.18423598709214659, -0.011223920663099322], \"y\": [-0.05580826859109278, 0.07217508565074929, -0.12695061296324192, 0.059309445132698986, 0.05127435077088646], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [17.376393789493854, 37.121068445388, 8.285267368250851, 23.68605493217278, 13.531215464694526]}, \"tinfo\": {\"Term\": [\"said\", \"state\", \"mrs\", \"government\", \"states\", \"mr\", \"united\", \"world\", \"brown\", \"tax\", \"feed\", \"west\", \"khrushchev\", \"fiscal\", \"soviet\", \"good\", \"peace\", \"president\", \"berlin\", \"use\", \"stations\", \"department\", \"corps\", \"property\", \"clay\", \"class\", \"administration\", \"000\", \"got\", \"1960\", \"revenues\", \"assessment\", \"wildlife\", \"boats\", \"forests\", \"va\", \"adjustment\", \"advantages\", \"clay\", \"tangible\", \"legislators\", \"hughes\", \"municipalities\", \"towns\", \"vehicles\", \"conservation\", \"lists\", \"lever\", \"clearing\", \"sizes\", \"instructions\", \"coordination\", \"cities\", \"districts\", \"forest\", \"planners\", \"bonds\", \"fishing\", \"exterior\", \"raises\", \"boat\", \"roads\", \"gun\", \"shooting\", \"property\", \"crisis\", \"site\", \"recreation\", \"aircraft\", \"signs\", \"vehicle\", \"inch\", \"planning\", \"system\", \"acres\", \"drill\", \"rhode\", \"available\", \"use\", \"motor\", \"state\", \"areas\", \"area\", \"small\", \"library\", \"island\", \"county\", \"pool\", \"000\", \"national\", \"city\", \"water\", \"miles\", \"range\", \"development\", \"large\", \"local\", \"public\", \"service\", \"cost\", \"american\", \"today\", \"program\", \"high\", \"place\", \"work\", \"people\", \"mrs\", \"mother\", \"ball\", \"shelter\", \"wasn\", \"player\", \"walked\", \"got\", \"daughter\", \"stopped\", \"hair\", \"baby\", \"didn\", \"oh\", \"went\", \"hadn\", \"sitting\", \"anne\", \"looked\", \"boy\", \"marriage\", \"maybe\", \"baseball\", \"pale\", \"sir\", \"smiled\", \"nice\", \"pink\", \"yards\", \"woman\", \"eyes\", \"couldn\", \"knew\", \"said\", \"told\", \"night\", \"gave\", \"room\", \"thought\", \"wanted\", \"son\", \"george\", \"ll\", \"left\", \"asked\", \"white\", \"god\", \"man\", \"came\", \"old\", \"know\", \"little\", \"young\", \"don\", \"john\", \"took\", \"home\", \"away\", \"come\", \"mr\", \"way\", \"good\", \"day\", \"right\", \"house\", \"think\", \"people\", \"week\", \"school\", \"santa\", \"tests\", \"clever\", \"dimensions\", \"stations\", \"revolution\", \"measurement\", \"precision\", \"khrushchev\", \"listeners\", \"bridge\", \"interference\", \"approaches\", \"36\", \"gear\", \"berlin\", \"musical\", \"signals\", \"knight\", \"generations\", \"creative\", \"foundation\", \"vernon\", \"movements\", \"lumber\", \"artistic\", \"allocation\", \"chamber\", \"twentieth\", \"monument\", \"china\", \"marketing\", \"soviet\", \"brown\", \"west\", \"volume\", \"formula\", \"machine\", \"af\", \"music\", \"world\", \"engine\", \"war\", \"mr\", \"good\", \"number\", \"men\", \"service\", \"class\", \"best\", \"great\", \"way\", \"right\", \"work\", \"company\", \"large\", \"cuba\", \"electronic\", \"yankees\", \"premier\", \"fiscal\", \"export\", \"calendar\", \"procurement\", \"filing\", \"farmers\", \"negotiations\", \"commodities\", \"payments\", \"india\", \"laos\", \"stocks\", \"allies\", \"recovery\", \"decline\", \"geneva\", \"adjustments\", \"amended\", \"1953\", \"authorized\", \"stockholders\", \"treasury\", \"expenditures\", \"external\", \"payment\", \"bankers\", \"income\", \"claim\", \"agreement\", \"machinery\", \"term\", \"shall\", \"billion\", \"review\", \"government\", \"secretary\", \"administration\", \"motors\", \"1960\", \"1959\", \"economic\", \"states\", \"sales\", \"officer\", \"military\", \"court\", \"report\", \"united\", \"department\", \"federal\", \"act\", \"tax\", \"president\", \"general\", \"medical\", \"research\", \"kennedy\", \"foreign\", \"communist\", \"state\", \"program\", \"business\", \"1961\", \"000\", \"million\", \"board\", \"development\", \"mr\", \"congo\", \"katanga\", \"academic\", \"collective\", \"prestige\", \"feed\", \"democrat\", \"trophy\", \"unions\", \"curriculum\", \"independence\", \"occur\", \"editorial\", \"employers\", \"cattle\", \"corps\", \"promoting\", \"teachers\", \"hiring\", \"philosopher\", \"fan\", \"editor\", \"cooling\", \"designer\", \"faculty\", \"ambition\", \"heating\", \"anti\", \"volunteers\", \"judging\", \"junior\", \"peace\", \"daily\", \"engineer\", \"chemical\", \"nations\", \"ballet\", \"trust\", \"catholic\", \"benefits\", \"interior\", \"freedom\", \"vacation\", \"class\", \"country\", \"labor\", \"american\", \"design\", \"university\", \"art\", \"day\", \"schools\", \"level\", \"work\", \"world\", \"company\", \"people\", \"united\", \"members\", \"public\", \"college\", \"week\", \"men\", \"state\", \"good\", \"house\"], \"Freq\": [796.0, 491.0, 306.0, 280.0, 339.0, 385.0, 305.0, 250.0, 95.0, 180.0, 95.0, 102.0, 69.0, 114.0, 77.0, 303.0, 107.0, 298.0, 62.0, 253.0, 56.0, 160.0, 74.0, 95.0, 80.0, 97.0, 135.0, 282.0, 146.0, 132.0, 20.069027180220267, 17.226793676976047, 16.28452813680227, 37.08304390102237, 15.339202843085307, 13.438111226454385, 13.430212810660638, 13.373115069439768, 75.31311857081039, 14.12834083317133, 12.238370308676222, 22.69084485790897, 8.709719339641179, 31.340279192453657, 38.918912716943915, 7.756133714202879, 7.736835355602384, 14.611384747437205, 8.543901443969778, 6.807493126704529, 9.343912089589447, 6.791085241863161, 46.662574621848975, 10.146309644640727, 36.98826307873541, 6.746954135973189, 28.549035084894733, 15.979709435924411, 5.871281198956169, 5.867367792224765, 36.86064928541644, 38.30300119676046, 17.493325850062458, 28.63332287163265, 79.74200811544898, 25.51569972373585, 43.946141501066535, 30.41351214230277, 46.114785063236475, 29.99051570597528, 18.682585039817333, 50.09760627983406, 60.64878291628507, 91.25887347861614, 25.468702159385032, 26.508605394304386, 56.367638540699836, 74.0469620787668, 130.11136753213438, 30.22034537605236, 203.97067776826276, 59.84211086431234, 78.3878352433741, 98.75008159707542, 33.177644833932675, 63.76023668041889, 58.055495458863575, 46.60225417163594, 102.6979680139275, 84.45999524493263, 83.61667057088377, 66.33004204616071, 41.097903852091015, 42.890781871163135, 68.24083872031578, 57.27174518239218, 53.615833275838895, 62.833403500084856, 61.74007850421068, 50.40194568957375, 63.02983433942765, 54.263176799234216, 58.79164771263896, 55.397968484503515, 53.58807600268537, 55.2184263250189, 55.17151422946423, 304.5530437868673, 96.56171427001284, 62.492937126122264, 59.55751319166115, 57.62469285593866, 47.89247160083795, 46.913807909546975, 143.9330233748466, 37.181188105445905, 36.20480492997822, 35.23770229503735, 35.237554617064035, 121.70454646203551, 33.26178585817598, 133.89964537530588, 31.344573320972838, 31.335923220378525, 34.17560912438114, 83.50491571047982, 80.51580943265144, 28.40131297137148, 35.96588046434374, 38.81614895243852, 26.47678264215133, 27.420876505364994, 26.473639484000017, 27.417836569481178, 25.495254930187205, 26.43839552320601, 53.80586082447611, 94.85489132882869, 51.76110161599237, 86.85907383970223, 722.8270558724377, 103.57360192467529, 139.29151294827022, 66.07569588292893, 95.73292740479279, 127.30285862311013, 66.6405619142117, 68.95373415630306, 49.21128953548394, 146.46535180983312, 141.45891268778914, 105.34813686536384, 107.0312716656973, 58.96984032899836, 224.54841944547002, 137.49460913713537, 199.75420859128732, 156.03717196716752, 185.39999787568578, 114.90423906061814, 140.3531298183725, 133.43816486386294, 101.01328752951483, 187.83022091982335, 102.98588739251761, 137.07566006960272, 208.53522626244023, 153.51767935482349, 159.83225166372995, 154.1633443576725, 130.48008729543548, 131.71365947666737, 103.27128820470666, 116.82793354598252, 107.29299065519645, 103.83971840438477, 16.47086072631191, 24.674397456964755, 5.60328756841831, 8.805260498704865, 49.52915975432215, 13.337968035971766, 10.048911063686576, 18.21390154070161, 56.58042112651673, 8.221811769795178, 40.238190805604894, 28.169209907159424, 6.494484955883058, 21.670563959253887, 16.493592879943844, 48.040881736533905, 15.038711162980274, 12.238862465946374, 8.781196431642982, 7.992274785715902, 11.2837661937956, 23.152489511862598, 13.903946730177198, 3.9411033691090025, 20.365235229120323, 5.893507462549995, 8.379629797090603, 18.701236192346467, 4.46084849076486, 7.044531484625876, 22.30108820511204, 28.044567272699034, 50.56417899291753, 61.692693593334674, 58.598449545810745, 26.236517353050996, 22.770692790939886, 26.954047682431103, 33.45412108645603, 27.846121435200626, 64.95944688841928, 16.318720030321096, 39.511704716691234, 64.85121496397724, 52.7670923427074, 34.4430042821491, 36.86672998128821, 36.038128580345784, 25.83038589165297, 26.277349374060336, 27.967518683303044, 29.587028320774962, 26.533131521172884, 26.473527101337147, 24.715805850037103, 23.01907026349658, 37.50648969013766, 26.789197922485013, 25.77722173366915, 24.815858555886457, 110.54882306118738, 22.853270664215415, 23.761071681860564, 18.911193266331157, 17.927267562701513, 17.92467286322719, 16.93190863944772, 16.930860318339402, 40.43563788078609, 36.52779055635509, 48.70813198454891, 14.971208734724492, 14.958707553901053, 13.964369128215587, 12.997535815602657, 12.99484524176199, 12.98782391824368, 12.016494257867553, 12.013904686459625, 29.570324832696688, 20.248472331263454, 26.72217373365542, 25.750120976595696, 11.024501929897644, 40.33664222791596, 11.001029398992387, 78.79670471324332, 41.99933578395481, 62.66447370630576, 31.61265225167575, 61.78058828114695, 113.7170247559618, 50.457919434533956, 26.287418541693636, 234.38077597471883, 107.50569697986984, 115.80233748792406, 42.45917172472211, 112.82842882447359, 57.39696510556203, 73.34135836516302, 268.6021239412584, 101.49894656252201, 48.89378529163823, 102.9390516629275, 91.59659949180582, 76.9321427505563, 224.00844509777426, 125.37105519123637, 93.53255312912047, 103.59865373706606, 129.61820967902653, 195.9288282742891, 134.2134661582574, 79.28837612048429, 80.19398334648774, 94.41502776556628, 77.64586488144054, 61.150724899192376, 227.6678360986656, 133.32330879443097, 122.46512733708093, 82.73391061758679, 132.960394270502, 86.83075420964002, 99.82363955656174, 101.58112837161529, 97.24979332592665, 41.42176956610462, 19.014767951849898, 27.50083384721621, 11.500983863268159, 11.480082901229965, 86.65835607209453, 7.6996306718594445, 7.698442145674489, 19.612357335538025, 7.660672178553563, 25.38631757609095, 6.716942420242917, 20.73017095572934, 7.434840071356481, 18.095007332529203, 64.91321248842611, 6.551349093230827, 29.39561746760079, 4.89717239574089, 4.884600377711382, 4.87519603999397, 43.9830198322113, 31.662377560173763, 15.335266235142099, 43.65905854471563, 5.47327058501152, 18.02881186783542, 47.4872508905955, 15.579245445278264, 9.31753249964338, 49.85156278876402, 80.14391499547781, 40.75362306822691, 25.993410860666977, 21.592189158906418, 56.33410217588384, 18.51189386824721, 27.89802913184358, 22.594173617691933, 19.74019597380456, 28.166210579460028, 32.93233055820484, 25.674932791263103, 50.61286156548083, 63.60507315828548, 37.09793353323655, 85.89032789396984, 38.64032469829295, 52.271537422338355, 32.40452225358985, 78.58009166307319, 41.03592045629227, 37.39144415276365, 61.1569615011207, 60.259505174888695, 44.13595859501848, 55.670704691480516, 58.01265622173245, 42.36949585969203, 45.27572127188159, 38.85356715642271, 42.34914066270266, 41.81217255217734, 45.38817907537397, 41.81836831290904, 40.72394591143974], \"Total\": [796.0, 491.0, 306.0, 280.0, 339.0, 385.0, 305.0, 250.0, 95.0, 180.0, 95.0, 102.0, 69.0, 114.0, 77.0, 303.0, 107.0, 298.0, 62.0, 253.0, 56.0, 160.0, 74.0, 95.0, 80.0, 97.0, 135.0, 282.0, 146.0, 132.0, 20.84010630088935, 17.998988993363874, 17.051751832530243, 38.861148689733994, 16.104658972608714, 14.210750656003237, 14.211205547969485, 14.213242819582744, 80.54202889631105, 15.148701611280295, 13.270913290902364, 24.66074154637142, 9.475493324649934, 34.123127375593, 42.54353430655937, 8.528581207662162, 8.529160808646237, 16.124897072797257, 9.473110360785334, 7.581425948910746, 10.431131170616313, 7.581896422260429, 52.22222842845784, 11.382214147191169, 41.528837540669144, 7.581091485345217, 32.192444472170294, 18.03364280623023, 6.6342769643989055, 6.634349205354711, 41.725668962693305, 43.62567688824856, 19.885920688122184, 33.13567340048615, 95.25246107982801, 29.448742783612538, 51.97895800579016, 36.08367312266736, 56.239427242395365, 36.10839069518349, 21.74729713743572, 67.28503233164902, 84.7497139801549, 141.61695660069597, 31.397503247851333, 33.207095834356245, 85.14216011726977, 120.1867975108694, 253.34969828256988, 40.00827644462156, 491.0202387451662, 98.66521842470497, 144.1359528399556, 209.2030070162257, 45.80024636237894, 118.380474163325, 103.46225167486, 77.4981987025677, 282.890916035654, 213.47958650730953, 212.5573665748491, 162.24044727859177, 65.6048600963717, 72.6792819088691, 201.17875190703853, 142.32931570575127, 129.6519280517885, 200.78757891934748, 204.48664872055102, 116.10216988900086, 260.1644311371174, 157.49043111918112, 233.23297781235982, 217.72309221880403, 189.49107525316782, 256.7853247432651, 262.257424210581, 306.57209342988557, 97.32300279050418, 63.25251128667954, 60.331665466475755, 58.38522086870767, 48.65084575897795, 47.67707548382141, 146.86524531296772, 37.94287780403474, 36.96936799420676, 35.996037379374556, 35.99604771737845, 124.47912581713193, 34.04807457280453, 137.07242929187979, 32.10227866266351, 32.10209543672518, 35.0200871644918, 85.65806895922938, 82.67305768787813, 29.182172293497413, 36.96187401568816, 39.893570824461484, 27.23503345235075, 28.207764668569403, 27.234935287779262, 28.206468407160706, 26.2613662984054, 27.235128144481813, 55.443725439455264, 98.21850982593952, 53.45461305142633, 90.40196898608941, 796.61312616069, 110.68568915694016, 151.2281304947594, 69.92360194395361, 102.9288424686558, 139.89243994293483, 70.93032424442453, 73.78219365155515, 51.58562664603175, 166.74745892691405, 161.62022327480565, 118.35847505610262, 121.37497675321323, 63.10959338753904, 280.5418572172119, 162.14914124945057, 251.79575566891637, 190.38525683794074, 236.66124651992146, 135.3968215141636, 176.69900485480255, 168.0979747520524, 119.92079366028464, 266.2364314510663, 123.12659018587497, 184.35504084563644, 385.69505446282506, 271.9689801675068, 303.78892414353965, 300.7734415939614, 212.63276390727736, 230.72816595124652, 133.28330396259685, 262.257424210581, 188.1884533347716, 171.29925316015067, 17.366948270456554, 26.5441430420702, 6.424287902810336, 10.100456095690236, 56.929069227446064, 15.5856824139959, 11.937220743467394, 22.030994067356485, 69.29568583756775, 10.153773696147645, 49.74177205279127, 35.067593430255066, 8.278291552470861, 27.623305709616677, 21.14709036185969, 62.04153727999629, 20.439543661819695, 16.675498801336623, 12.060737080863019, 11.09486614714629, 15.674576692381747, 32.43404266138909, 19.488466710058475, 5.538381094471793, 28.67176217261909, 8.326163698634462, 12.034259430102876, 26.86925057101301, 6.467514715114234, 10.21929402581527, 32.474505297019114, 41.0617533583738, 77.5980676945738, 95.94101744975461, 102.78276743047816, 42.84483595019932, 36.56217261342505, 51.69215122545828, 72.61456549642683, 60.43550205851625, 250.40356281410945, 28.79491263572677, 143.34006271834951, 385.69505446282506, 303.78892414353965, 134.84010992842906, 190.98012945895994, 204.48664872055102, 97.84868070527119, 137.14890412416838, 199.5158305549932, 271.9689801675068, 212.63276390727736, 256.7853247432651, 138.35509011742215, 142.32931570575127, 38.385073534626954, 27.550120014152206, 26.564811463171935, 25.579695735253026, 114.12781383679015, 23.60983228215293, 24.594000144914677, 19.669283291079214, 18.6842290234534, 18.68413311512488, 17.698520911721523, 17.698597333738856, 42.28334700532045, 38.33966289761283, 51.172635333549714, 15.728813414577221, 15.7282389887617, 14.742594407710307, 13.758385689263333, 13.758102118614094, 13.758070228523897, 12.773459038115616, 12.77335127828899, 31.445837216737505, 21.612505720800208, 28.522816268594955, 27.50574127235385, 11.787998198646859, 43.217587748997005, 11.787183703585455, 84.51979043475323, 45.14003097040305, 67.8399872998423, 34.29105068032181, 68.66479051833949, 130.2653467258358, 55.91065279063269, 28.477707674338433, 280.9560723120668, 124.58201316709369, 135.14309090814015, 47.09225516013769, 132.1822078416864, 64.71660489994639, 84.08385843026453, 339.69112998577714, 120.29829560101857, 55.014272991149916, 124.22604325778987, 109.67406696118482, 91.06223658442751, 305.5628712707981, 160.06634546924374, 116.38712547566931, 133.69674886785822, 180.21077609378654, 298.3829575103132, 202.62679002214472, 103.42353137656177, 105.19959201003459, 132.26168923019242, 102.59416224120932, 74.38166917439737, 491.0202387451662, 233.23297781235982, 212.60968644719, 116.7969745433318, 282.890916035654, 131.2236463942333, 177.39902968659854, 201.17875190703853, 385.69505446282506, 42.45444384436024, 19.812976768547347, 29.211040002653643, 12.268791462773041, 12.2692120807924, 95.2719043322915, 8.497453946881613, 8.49743702488773, 21.745711047337647, 8.49965795716313, 28.356147284396947, 7.553908731450257, 23.603016981128878, 8.486882129711283, 20.7553417660536, 74.886440165331, 7.5640352474252825, 33.975602351890316, 5.667550576717418, 5.667536817568901, 5.668136948429076, 51.1776660440796, 36.934663990630675, 17.95327162214651, 52.203096371482474, 6.61216682651684, 21.792283875339358, 57.40857372049398, 18.95113631819277, 11.365719259354924, 63.600370903575566, 107.56362926715074, 53.14051847581358, 33.17953093633785, 27.58041096983117, 78.18651548151843, 23.572247502795136, 38.05573497000594, 31.08111216565543, 26.541863838312892, 40.961232785392134, 51.92062100090108, 37.86340713158357, 97.84868070527119, 143.0812596791991, 68.79027391760881, 260.1644311371174, 74.64547210391002, 124.14219265367132, 58.08295034209759, 300.7734415939614, 90.336526387883, 83.64354439706892, 256.7853247432651, 250.40356281410945, 138.35509011742215, 262.257424210581, 305.5628712707981, 140.73026524875547, 200.78757891934748, 124.66066306693295, 188.1884533347716, 190.98012945895994, 491.0202387451662, 303.78892414353965, 230.72816595124652], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.9841, -7.1368, -7.1931, -6.3701, -7.2529, -7.3852, -7.3858, -7.3901, -5.6616, -7.3351, -7.4787, -6.8613, -7.8189, -6.5384, -6.3218, -7.9348, -7.9373, -7.3015, -7.8381, -8.0653, -7.7486, -8.0677, -6.1404, -7.6662, -6.3727, -8.0742, -6.6317, -7.212, -8.2132, -8.2139, -6.3762, -6.3378, -7.1215, -6.6287, -5.6045, -6.744, -6.2003, -6.5684, -6.1522, -6.5824, -7.0557, -6.0693, -5.8782, -5.4696, -6.7459, -6.7058, -5.9514, -5.6786, -5.1149, -6.5748, -4.6653, -5.8916, -5.6216, -5.3907, -6.4814, -5.8282, -5.9219, -6.1417, -5.3515, -5.547, -5.5571, -5.7887, -6.2673, -6.2246, -5.7603, -5.9355, -6.0015, -5.8428, -5.8604, -6.0633, -5.8397, -5.9895, -5.9093, -5.9688, -6.002, -5.972, -5.9729, -5.0235, -6.1722, -6.6073, -6.6554, -6.6884, -6.8734, -6.8941, -5.773, -7.1266, -7.1532, -7.1803, -7.1803, -5.9408, -7.238, -5.8453, -7.2973, -7.2976, -7.2109, -6.3175, -6.3539, -7.3959, -7.1598, -7.0835, -7.4661, -7.4311, -7.4662, -7.4312, -7.5039, -7.4676, -6.757, -6.19, -6.7957, -6.2781, -4.1592, -6.1021, -5.8058, -6.5516, -6.1808, -5.8958, -6.5431, -6.5089, -6.8463, -5.7556, -5.7904, -6.0851, -6.0693, -6.6653, -5.3283, -5.8188, -5.4453, -5.6923, -5.5199, -5.9983, -5.7982, -5.8487, -6.1271, -5.5068, -6.1078, -5.8218, -5.4023, -5.7086, -5.6683, -5.7044, -5.8712, -5.8617, -6.105, -5.9817, -6.0668, -6.0995, -6.4411, -6.0369, -7.5193, -7.0673, -5.3401, -6.6521, -6.9352, -6.3405, -5.207, -7.1359, -5.5479, -5.9044, -7.3717, -6.1667, -6.4397, -5.3706, -6.532, -6.7381, -7.0701, -7.1642, -6.8193, -6.1006, -6.6105, -7.8712, -6.2288, -7.4688, -7.1169, -6.3141, -7.7473, -7.2904, -6.138, -5.9089, -5.3194, -5.1205, -5.172, -5.9755, -6.1172, -5.9485, -5.7325, -5.916, -5.0689, -6.4504, -5.5661, -5.0706, -5.2768, -5.7034, -5.6354, -5.6581, -5.9911, -5.974, -5.9116, -5.8553, -5.9643, -5.9665, -6.0352, -6.1063, -6.6686, -7.0051, -7.0436, -7.0816, -5.5876, -7.164, -7.125, -7.3533, -7.4068, -7.4069, -7.4639, -7.4639, -6.5934, -6.695, -6.4072, -7.5869, -7.5878, -7.6566, -7.7283, -7.7285, -7.7291, -7.8068, -7.807, -6.9063, -7.285, -7.0076, -7.0446, -7.893, -6.5958, -7.8951, -5.9262, -6.5554, -6.1553, -6.8395, -6.1695, -5.5594, -6.3719, -7.024, -4.8361, -5.6155, -5.5412, -6.5445, -5.5672, -6.2431, -5.998, -4.6998, -5.673, -6.4034, -5.6589, -5.7757, -5.9502, -4.8814, -5.4618, -5.7548, -5.6526, -5.4285, -5.0153, -5.3936, -5.92, -5.9086, -5.7454, -5.9409, -6.1797, -4.8652, -5.4003, -5.4853, -5.8774, -5.403, -5.8291, -5.6897, -5.6722, -5.7158, -6.0094, -6.788, -6.419, -7.2908, -7.2926, -5.2712, -7.692, -7.6922, -6.757, -7.6971, -6.499, -7.8286, -6.7016, -7.727, -6.8376, -5.5601, -7.8535, -6.3523, -8.1445, -8.1471, -8.149, -5.9494, -6.2781, -7.003, -5.9568, -8.0333, -6.8412, -5.8727, -6.9873, -7.5013, -5.8241, -5.3494, -6.0256, -6.4753, -6.6609, -5.7019, -6.8148, -6.4046, -6.6155, -6.7505, -6.3951, -6.2387, -6.4877, -5.809, -5.5805, -6.1196, -5.2801, -6.0789, -5.7767, -6.2549, -5.3691, -6.0187, -6.1117, -5.6197, -5.6345, -5.9459, -5.7137, -5.6725, -5.9868, -5.9204, -6.0734, -5.9872, -6.0, -5.9179, -5.9999, -6.0264], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.7124, 1.7062, 1.704, 1.7032, 1.7014, 1.6942, 1.6935, 1.6891, 1.6829, 1.6803, 1.6691, 1.6668, 1.6658, 1.665, 1.661, 1.6551, 1.6526, 1.6515, 1.6468, 1.6424, 1.64, 1.6399, 1.6375, 1.6351, 1.6343, 1.6335, 1.6299, 1.6291, 1.6279, 1.6272, 1.6261, 1.6199, 1.6219, 1.604, 1.5723, 1.6067, 1.5822, 1.5791, 1.5516, 1.5644, 1.5982, 1.4551, 1.4155, 1.3106, 1.5408, 1.5248, 1.3376, 1.2657, 1.0837, 1.4695, 0.8715, 1.25, 1.141, 0.9993, 1.4276, 1.1313, 1.1723, 1.2415, 0.7368, 0.8228, 0.8171, 0.8556, 1.2824, 1.2227, 0.6689, 0.8397, 0.867, 0.5883, 0.5525, 0.9156, 0.3324, 0.6845, 0.372, 0.3814, 0.487, 0.2131, 0.1912, 0.9844, 0.9831, 0.9789, 0.9781, 0.9779, 0.9753, 0.9748, 0.9708, 0.9707, 0.9701, 0.9697, 0.9697, 0.9684, 0.9676, 0.9676, 0.9671, 0.9668, 0.9666, 0.9655, 0.9645, 0.9639, 0.9637, 0.9636, 0.9627, 0.9627, 0.9626, 0.9626, 0.9614, 0.9613, 0.961, 0.9561, 0.9588, 0.951, 0.8938, 0.9246, 0.9088, 0.9344, 0.9185, 0.8967, 0.9286, 0.9233, 0.9439, 0.8613, 0.8577, 0.8745, 0.8652, 0.9231, 0.7684, 0.8261, 0.7595, 0.792, 0.7469, 0.8269, 0.7607, 0.7601, 0.8194, 0.6421, 0.8124, 0.6947, 0.376, 0.4191, 0.3488, 0.3226, 0.5026, 0.4304, 0.7359, 0.1824, 0.4291, 0.4904, 2.4377, 2.4176, 2.354, 2.3535, 2.3514, 2.335, 2.3185, 2.3004, 2.288, 2.2796, 2.2787, 2.2716, 2.248, 2.248, 2.2422, 2.2349, 2.1838, 2.1814, 2.1733, 2.1627, 2.162, 2.1536, 2.153, 2.1504, 2.1486, 2.1451, 2.1287, 2.1283, 2.1192, 2.1187, 2.1149, 2.1094, 2.0624, 2.0491, 1.9288, 2.0003, 2.0172, 1.8395, 1.7157, 1.7158, 1.1414, 1.9228, 1.2021, 0.7077, 0.7402, 1.1259, 0.8458, 0.7548, 1.1588, 0.8383, 0.5258, 0.2723, 0.4095, 0.2186, 0.7683, 0.6689, 1.4171, 1.4123, 1.4102, 1.41, 1.4084, 1.4077, 1.4058, 1.401, 1.3989, 1.3988, 1.396, 1.3959, 1.3956, 1.3919, 1.3909, 1.3909, 1.3901, 1.3861, 1.3834, 1.3832, 1.3827, 1.3792, 1.379, 1.3788, 1.3751, 1.3751, 1.3743, 1.3733, 1.3713, 1.3713, 1.3702, 1.3682, 1.3609, 1.359, 1.3346, 1.3044, 1.3377, 1.3603, 1.259, 1.2929, 1.2858, 1.3367, 1.282, 1.3203, 1.3036, 1.2055, 1.2704, 1.3223, 1.2523, 1.2602, 1.2717, 1.1298, 1.196, 1.2217, 1.1852, 1.1107, 1.0197, 1.0283, 1.1745, 1.1689, 1.1032, 1.1617, 1.2444, 0.6717, 0.881, 0.8887, 1.0955, 0.6853, 1.0273, 0.8653, 0.7569, 0.0625, 1.9755, 1.959, 1.9398, 1.9355, 1.9337, 1.9054, 1.9016, 1.9014, 1.8969, 1.8962, 1.8895, 1.8827, 1.8704, 1.8678, 1.863, 1.8572, 1.8564, 1.8554, 1.8541, 1.8515, 1.8495, 1.8487, 1.8461, 1.8426, 1.8214, 1.8111, 1.8106, 1.8104, 1.8042, 1.8015, 1.7566, 1.7059, 1.7348, 1.7561, 1.7554, 1.6724, 1.7585, 1.6897, 1.6813, 1.7041, 1.6257, 1.5449, 1.6117, 1.341, 1.1895, 1.3827, 0.8919, 1.3417, 1.1352, 1.4166, 0.6579, 1.2111, 1.195, 0.5654, 0.5758, 0.8576, 0.4503, 0.3387, 0.7998, 0.5107, 0.8344, 0.5087, 0.4812, -0.3811, 0.0172, 0.2657]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 4, 1, 4, 5, 1, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 3, 5, 1, 2, 1, 2, 3, 4, 5, 1, 4, 1, 4, 5, 1, 1, 2, 3, 5, 1, 2, 4, 1, 4, 4, 3, 4, 5, 1, 5, 4, 1, 2, 3, 4, 5, 2, 2, 3, 5, 3, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 5, 1, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 2, 2, 3, 5, 4, 2, 4, 1, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 4, 5, 1, 2, 3, 1, 2, 1, 5, 2, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 4, 2, 3, 4, 2, 3, 4, 5, 2, 3, 5, 2, 3, 5, 4, 5, 1, 2, 3, 1, 2, 1, 2, 3, 4, 5, 3, 4, 5, 2, 3, 5, 1, 2, 3, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 5, 1, 2, 4, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 2, 3, 4, 5, 3, 4, 5, 1, 2, 4, 5, 1, 2, 4, 5, 2, 1, 2, 3, 4, 5, 4, 5, 1, 4, 5, 1, 3, 4, 5, 1, 4, 5, 1, 3, 4, 5, 2, 3, 5, 2, 3, 1, 2, 1, 2, 3, 5, 1, 2, 3, 3, 4, 5, 2, 4, 5, 1, 5, 4, 5, 1, 2, 3, 1, 2, 5, 4, 5, 4, 1, 4, 1, 2, 5, 2, 4, 5, 5, 4, 1, 2, 4, 5, 1, 2, 3, 5, 4, 1, 4, 1, 2, 1, 2, 3, 4, 5, 1, 3, 1, 3, 4, 2, 3, 4, 5, 1, 2, 3, 5, 2, 3, 5, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 2, 4, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 5, 2, 2, 2, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 2, 4, 5, 1, 4, 5, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 2, 5, 2, 5, 5, 1, 2, 3, 4, 5, 3, 4, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 1, 2, 3, 4, 5, 1, 2, 1, 2, 4, 3, 4, 1, 1, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 3, 4, 2, 2, 1, 3, 1, 2, 4, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 4, 5, 1, 2, 4, 5, 2, 3, 2, 1, 2, 4, 5, 1, 4, 5, 3, 5, 1, 2, 3, 4, 5, 2, 5, 1, 1, 2, 3, 4, 3, 4, 1, 2, 3, 4, 5, 2, 3, 4, 5, 4, 2, 1, 2, 3, 5, 1, 2, 3, 4, 5, 5, 2, 4, 5, 2, 1, 2, 3, 4, 5, 2, 4, 5, 1, 4, 1, 2, 3, 5, 1, 2, 3, 4, 5, 5, 2, 1, 2, 3, 4, 5, 1, 1, 3, 4, 5, 2, 1, 2, 5, 1, 3, 4, 1, 2, 3, 4, 5, 5, 4, 1, 2, 3, 4, 5, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 4, 1, 4, 5, 2, 4, 5, 1, 2, 3, 4, 5, 1, 1, 4, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 5, 2, 3, 1, 2, 4, 5, 2, 1, 3, 4, 2, 1, 1, 2, 3, 4, 5, 2, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 4, 5, 4, 2, 1, 2, 3, 4, 5, 1, 1, 4, 1, 5, 1, 4, 5, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 5, 2, 4, 5, 1, 3, 4, 5, 1, 3, 2, 4, 5, 1, 2, 3, 4, 5, 2, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 5, 1, 3, 5, 1, 3, 5, 2, 3, 1, 2, 3, 4, 2, 5, 2, 1, 2, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 2, 1, 2, 3, 5], \"Freq\": [0.3640979408013881, 0.0919082180663698, 0.03534931464091146, 0.47014588472412244, 0.03888424610500261, 0.9394558826857393, 0.09271190924301671, 0.8807631378086587, 0.015451984873836118, 0.09078377639426562, 0.8548805610460012, 0.05295720289665494, 0.08561865612614811, 0.034247462450459246, 0.017123731225229623, 0.7106348458470293, 0.1541135810270666, 0.1448052612547185, 0.07240263062735924, 0.7964289369009517, 0.03423363221265508, 0.9585417019543423, 0.7962416566263388, 0.15924833132526778, 0.04487768065273013, 0.04487768065273013, 0.029918453768486755, 0.7778797979806557, 0.11219420163182534, 0.9147710907508094, 0.9448999593742275, 0.09619433677772249, 0.8583494666319853, 0.04439738620510269, 0.9146399709775478, 0.4819969624650891, 0.027542683569433665, 0.45445427889565543, 0.027542683569433665, 0.029481137594562154, 0.04422170639184323, 0.9286558342287078, 0.8179315162961598, 0.1600300792753356, 0.953698631532618, 0.6647687833609892, 0.08309609792012365, 0.1661921958402473, 0.15123635356411302, 0.7561817678205651, 0.9394479572206997, 0.24215454712483891, 0.23831082415460336, 0.030749783761884305, 0.15374891880942154, 0.3305601754402563, 0.9708713699169171, 0.05225700284083257, 0.10451400568166513, 0.8186930445063769, 0.7247872295835185, 0.12079787159725308, 0.541155752351455, 0.11794420243557352, 0.09713051965282525, 0.06937894260916089, 0.17344735652290222, 0.608117034127768, 0.0912175551191652, 0.152029258531942, 0.14189397462981254, 0.06886702511564506, 0.3099016130204028, 0.03443351255782253, 0.017216756278911265, 0.5509362009251605, 0.12010333164167859, 0.12010333164167859, 0.7206199898500716, 0.04224454562827014, 0.8871354581936729, 0.05914236387957819, 0.9444974940685726, 0.03180071158886924, 0.9540213476660772, 0.615708226964843, 0.008320381445470851, 0.02496114433641255, 0.21632991758224213, 0.13312610312753362, 0.09746067020847812, 0.8365374192894373, 0.016243445034746354, 0.03248689006949271, 0.02436516755211953, 0.9723289699691788, 0.9801982362249179, 0.08484553709877878, 0.08484553709877878, 0.8060326024383984, 0.9332169818184807, 0.9776011320622727, 0.025066695693904427, 0.15070531686723687, 0.11302898765042764, 0.7535265843361844, 0.08059116874288223, 0.7736752199316694, 0.12894586998861157, 0.1458269034500845, 0.4010239844877324, 0.18957497448510988, 0.08020479689754648, 0.18228362931260564, 0.07154271682319122, 0.017885679205797804, 0.8942839602898902, 0.18602131059171717, 0.24802841412228954, 0.5637009411870217, 0.005637009411870217, 0.8867443211774867, 0.07189818820358, 0.02396606273452667, 0.952107728348605, 0.025732641306719053, 0.9008324927008853, 0.0931895682104364, 0.9797629634772365, 0.012095839055274523, 0.060311482204857526, 0.12062296440971505, 0.804153096064767, 0.05211535308783395, 0.3022690479094369, 0.646230378289141, 0.10347600040068997, 0.16932436429203812, 0.05173800020034498, 0.5738214567674625, 0.09877254583702223, 0.9758477619982653, 0.8449011752041222, 0.05550445676523431, 0.09867458980486099, 0.09652164259794392, 0.1608694043299065, 0.0321738808659813, 0.73999925991757, 0.048180367795029516, 0.048180367795029516, 0.8672466203105313, 0.1860863214917532, 0.7071280216686622, 0.11165179289505192, 0.1812880890523803, 0.7976675918304733, 0.09238016014597687, 0.21555370700727938, 0.6774545077371638, 0.899999893041484, 0.0957446694724983, 0.3951874327085275, 0.4187104941792732, 0.014113836882447411, 0.018818449176596547, 0.15525220570692153, 0.022153285642530232, 0.9304379969862697, 0.022153285642530232, 0.214617099061906, 0.2657164083623598, 0.5212129548646289, 0.9311908456708261, 0.03724763382683304, 0.012415877942277682, 0.9500575478626523, 0.9339556524817747, 0.9780914474266981, 0.016043553361545636, 0.28878396050782146, 0.016043553361545636, 0.3609799506347768, 0.3128492905501399, 0.14103221631878368, 0.7431312936797448, 0.032545896073565464, 0.005424316012260911, 0.07594042417165275, 0.9605280960651543, 0.04033251785417876, 0.0941092083264171, 0.05377669047223835, 0.8200945297016348, 0.04336667335410495, 0.1734666934164198, 0.18069447230877062, 0.289111155694033, 0.3180222712634363, 0.9657410694227372, 0.938022375024432, 0.1082993472206676, 0.0270748368051669, 0.8663947777653408, 0.9232518634055745, 0.026707104725294563, 0.10682841890117825, 0.8679809035720734, 0.4306551724899057, 0.017226206899596228, 0.12058344829717359, 0.2497800000441453, 0.17226206899596228, 0.9727878854903148, 0.018707459336352206, 0.21666009978878265, 0.20268202883466765, 0.020967106431172514, 0.11182456763292008, 0.4472982705316803, 0.5605909310989146, 0.25129938290640996, 0.028996082643047306, 0.1546457740962523, 0.10029718332496097, 0.054707554540887805, 0.8388491696269463, 0.009117925756814634, 0.7017733375438641, 0.06379757614035128, 0.19139272842105384, 0.8828899824704343, 0.10187192105428088, 0.9899681438859409, 0.9412143453676226, 0.05645409728859575, 0.0940901621476596, 0.07527212971812768, 0.7715393296108086, 0.9751500714072228, 0.0930933258322704, 0.5120132920774871, 0.0465466629161352, 0.08976856419540359, 0.2626561693124772, 0.9448782941260938, 0.9414584709736299, 0.07496891345161474, 0.7809261817876536, 0.13744300799462703, 0.3751064761305639, 0.053586639447223416, 0.053586639447223416, 0.5224697346104283, 0.11140030865086852, 0.05570015432543426, 0.8355023148815138, 0.3380078629348576, 0.07953126186702532, 0.5070117944022864, 0.07456055800033623, 0.980084003636289, 0.008033475439641712, 0.008033475439641712, 0.09900543010396234, 0.8910488709356611, 0.8785636845945072, 0.08785636845945072, 0.03961539005696186, 0.7923078011392372, 0.050934072930379534, 0.11318682873417674, 0.8130792326640516, 0.15057022827112065, 0.060228091308448264, 0.05946444529715274, 0.86818090133843, 0.05946444529715274, 0.03907954689214215, 0.0781590937842843, 0.8597500316271274, 0.08473493035229536, 0.8897167686991012, 0.9800320283951716, 0.8248023117340189, 0.3472835679866825, 0.06945671359733649, 0.5556537087786919, 0.060278127615409495, 0.15069531903852373, 0.7836156590003234, 0.9452572007623995, 0.03635604618316921, 0.9741704102398935, 0.9043939576531723, 0.933152500927824, 0.02036276057888021, 0.9672311274968101, 0.010181380289440106, 0.01915595184017246, 0.13409166288120722, 0.8428618809675883, 0.8821240639546915, 0.9633842731204334, 0.14606426553213434, 0.025776046858611942, 0.8076494682365076, 0.01718403123907463, 0.052481369350620796, 0.02099254774024832, 0.02099254774024832, 0.9131758267008019, 0.9633793279565069, 0.026286317937275008, 0.9725937636791754, 0.8872306151296481, 0.055451913445603004, 0.019494286578390262, 0.09747143289195132, 0.009747143289195131, 0.7602771765572203, 0.11696571947034158, 0.8909471632517029, 0.09631861224342735, 0.9314074905598715, 0.6290654618143443, 0.35555873928636855, 0.15415901286805112, 0.7091314591930351, 0.06166360514722045, 0.06166360514722045, 0.15408136200568864, 0.11556102150426649, 0.0963008512535554, 0.6355856182734657, 0.9438873022145151, 0.014301322760825986, 0.02860264552165197, 0.14186348801018592, 0.7566052693876582, 0.047287829336728635, 0.1036388130005166, 0.03948145257162537, 0.07896290514325074, 0.661314330574725, 0.11350917614342294, 0.09013177687206349, 0.09013177687206349, 0.7210542149765079, 0.9448977691778857, 0.9498769945400934, 0.03877048957306504, 0.9348816373716253, 0.015845451480875006, 0.047536354442625016, 0.11850333286999652, 0.5266814794222068, 0.17446324005860597, 0.04608462944944309, 0.13825388834832927, 0.006808962854819835, 0.9804906510940562, 0.006808962854819835, 0.06050767958173035, 0.02491492688659485, 0.8328704130661707, 0.07830405592929811, 0.20048534438962562, 0.3608736199013261, 0.14033974107273794, 0.1102669394142941, 0.1854489435604037, 0.8548761843425264, 0.10057366874617958, 0.9656635382725803, 0.9723292492204912, 0.13766340495384552, 0.8259804297230732, 0.25261445370584273, 0.3582532252555588, 0.08726681128020022, 0.17453362256040045, 0.12860372188661084, 0.8822153295888088, 0.09014543903399316, 0.7061392724329465, 0.026292419718248007, 0.10141361891324231, 0.07512119919499431, 0.09968440526181775, 0.572101804111302, 0.07367977780221313, 0.0780138823788139, 0.17769828764063167, 0.9326564635840896, 0.0405502810253952, 0.7431073192259043, 0.14862146384518085, 0.08917287830710852, 0.023663097006185085, 0.9346923317443109, 0.04732619401237017, 0.03526572174881645, 0.03526572174881645, 0.8816430437204114, 0.9650580418197614, 0.026082649778912472, 0.8628019198293951, 0.0958668799810439, 0.798457985310238, 0.14258178309111394, 0.05703271323644558, 0.024413327724760927, 0.024413327724760927, 0.24413327724760925, 0.6835731762933059, 0.540629698033661, 0.10981540741308739, 0.08447339031775952, 0.03378935612710381, 0.23652549288972666, 0.7912052491779121, 0.04759129318363381, 0.01784673494386268, 0.1368249679029472, 0.08798387301154897, 0.7918548571039408, 0.20440132369210995, 0.7861589372773459, 0.9589674596581605, 0.022682305189514897, 0.22682305189514898, 0.007560768396504966, 0.7107122292714668, 0.030243073586019863, 0.8225620298154002, 0.1731709536453474, 0.9623684193580685, 0.011061705969632971, 0.011061705969632971, 0.011061705969632971, 0.1658273442651722, 0.746223049193275, 0.0829136721325861, 0.036767552888606926, 0.8193911786603829, 0.04727256799963748, 0.09979764355479023, 0.014536938771282051, 0.058147755085128205, 0.07268469385641026, 0.3198126529682051, 0.5378667345374358, 0.039083388747985066, 0.9575430243256342, 0.40047968837172404, 0.17564898612794916, 0.16159706723771322, 0.10538939167676949, 0.15457110779259525, 0.043311411518704435, 0.8724155748767607, 0.05568610052404856, 0.018562033508016187, 0.9042331704650941, 0.274976391373558, 0.04782198110844487, 0.05977747638555609, 0.16737693387955704, 0.44235332525311505, 0.9302384959284509, 0.06201589972856339, 0.720520141723664, 0.24017338057455465, 0.04366788737719175, 0.7878844102104826, 0.09848555127631033, 0.9379586315092321, 0.0633817332604024, 0.781708043544963, 0.03802903995624145, 0.008450897768053654, 0.10563622210067068, 0.8755755616281521, 0.005997092887864056, 0.11394476486941706, 0.41649978377822583, 0.05399071271199223, 0.06170367167084827, 0.3933609069016577, 0.08484254854741637, 0.9806431667281856, 0.023348646826861563, 0.13951008577421561, 0.13951008577421561, 0.6975504288710781, 0.019345296651293205, 0.5223230095849165, 0.3288700430719845, 0.13541707655905244, 0.05832425546376495, 0.9331880874202392, 0.06416154857798403, 0.8020193572248003, 0.017822652382773342, 0.014258121906218673, 0.10337138382008539, 0.6818997658386623, 0.29224275678799816, 0.9594899145407063, 0.9739765896263837, 0.0837715931949442, 0.837715931949442, 0.11602775345495005, 0.00966897945457917, 0.7638493769117545, 0.10635877400037089, 0.1065868807501068, 0.3410780184003418, 0.2487027217502492, 0.2984432661002991, 0.020944587331320073, 0.4503086276233816, 0.19373743281471068, 0.11519523032226041, 0.21991816697886077, 0.6249536991584488, 0.2438843704032971, 0.06097109260082428, 0.06097109260082428, 0.12074762752342104, 0.8291337089941577, 0.04829905100936841, 0.3200642655045571, 0.007620577750108502, 0.6629902642594396, 0.007620577750108502, 0.2935623529787487, 0.6849788236170803, 0.9966811259286824, 0.7498448487658608, 0.12497414146097678, 0.07498448487658607, 0.04998965658439072, 0.0637047427395114, 0.8918663983531597, 0.0212349142465038, 0.7222327123701638, 0.18055817809254096, 0.033705384213716945, 0.5418788692820647, 0.16852692106858472, 0.2514940206715803, 0.0051854437251872216, 0.994872026960128, 0.003261875498229928, 0.9498186206925009, 0.016546565610255987, 0.41366414025639975, 0.4633038370871677, 0.09927939366153593, 0.7338715701378128, 0.24462385671260428, 0.3934802449934661, 0.1733186793423601, 0.05621146357049516, 0.22953014291285523, 0.1498972361879871, 0.02557985846642259, 0.012789929233211294, 0.2430086554310146, 0.7162360370598325, 0.9605322436148378, 0.9572272434200084, 0.019837579094479123, 0.919141164710866, 0.052900210918610996, 0.0066125263648263745, 0.27439906434101097, 0.11865905485016691, 0.2521504915566047, 0.08899429113762519, 0.25956668248474013, 0.9266725676543999, 0.07270840424708468, 0.8906779520267872, 0.03635420212354234, 0.9692178020062941, 0.03574325538605983, 0.7942945641346629, 0.08340092923413961, 0.007942945641346628, 0.07942945641346628, 0.9546527653615146, 0.9255491128360889, 0.046277455641804445, 0.023649972644648295, 0.9459989057859317, 0.018593645581004837, 0.13015551906703385, 0.1022650506955266, 0.7437458232401934, 0.20971760919850052, 0.4461265504768102, 0.07244790135948201, 0.057195711599591054, 0.21353065663847326, 0.8822174713537649, 0.9519687481575553, 0.28497384337417364, 0.4855109924152588, 0.05277293395818031, 0.11610045470799667, 0.06332752074981637, 0.9233498914412908, 0.7197664409142884, 0.05899724925526954, 0.20059064746791644, 0.023598899702107816, 0.9866221080266041, 0.6064657087112758, 0.37420224580057443, 0.012903525717261187, 0.13617179464657594, 0.8170307678794556, 0.9773376610397242, 0.02681118273895885, 0.17427268780323252, 0.020108387054219135, 0.6568739771044917, 0.12065032232531481, 0.8965530897636559, 0.965973173441314, 0.25296594226682034, 0.025725350061032576, 0.021437791717527147, 0.5702452596862221, 0.12862675030516288, 0.9254319646887851, 0.8398733123856462, 0.010498416404820578, 0.13647941326266752, 0.31376442875137156, 0.059764653095499345, 0.024901938789791394, 0.3785094696048292, 0.22411744910812256, 0.9043841097718046, 0.5916404079764674, 0.04127723776580005, 0.04127723776580005, 0.2751815851053337, 0.05503631702106673, 0.9496293266182556, 0.8314009468496801, 0.08314009468496801, 0.055426729789978674, 0.021963001075047377, 0.845575541389324, 0.12079650591276057, 0.028517220862547085, 0.019011480575031388, 0.04752870143757847, 0.7604592230012556, 0.1425861043127354, 0.9596880030859777, 0.07023037187091506, 0.9129948343218959, 0.8340988642451764, 0.1283229021915656, 0.6577235052865574, 0.01174506259440281, 0.02349012518880562, 0.01174506259440281, 0.28188150226566744, 0.07054416132473847, 0.6113827314810667, 0.12697949038452924, 0.10816771403126564, 0.07995004950137026, 0.8710466567049656, 0.06876684131881308, 0.04584456087920872, 0.01943089956159806, 0.9326831789567069, 0.00971544978079903, 0.03886179912319612, 0.021340346325866115, 0.9075923760941883, 0.011297830407811472, 0.05648915203905736, 0.003765943469270491, 0.04987601835939227, 0.03325067890626151, 0.04987601835939227, 0.8395796423831031, 0.016625339453130755, 0.9212902434458269, 0.19264532326447287, 0.6071246551365205, 0.00583773706862039, 0.01167547413724078, 0.18096984912723207, 0.33209158243684644, 0.12176691356017702, 0.011069719414561549, 0.08855775531649239, 0.45385849599702344, 0.06421472728386661, 0.048161045462899954, 0.8668988183321992, 0.024080522731449977, 0.3031982791440259, 0.09780589649807288, 0.1760506136965312, 0.3472109325681587, 0.07824471719845831, 0.03838319342536506, 0.03838319342536506, 0.03838319342536506, 0.8751368100983232, 0.015353277370146022, 0.994502630353209, 0.8751896981087014, 0.12071582042878641, 0.23987288462276046, 0.7196186538682814, 0.8308318211479226, 0.11077757615305635, 0.027694394038264087, 0.027694394038264087, 0.957183254938483, 0.8464963840771615, 0.09619277091785927, 0.03847710836714371, 0.9656690498943452, 0.9233091567696072, 0.4732245554784095, 0.30114289894080604, 0.07170069022400144, 0.09082087428373516, 0.06692064420906801, 0.9546562062758638, 0.9351849895634765, 0.04066021693754245, 0.013553405645847486, 0.012886918833288512, 0.025773837666577024, 0.6572328604977141, 0.3092860519989243, 0.41546148998121774, 0.028512063037926708, 0.46433931233194925, 0.09164591690762156, 0.08831552357948264, 0.02060695550187928, 0.02649465707384479, 0.791895861429361, 0.07654012043555161, 0.052697155262002256, 0.01756571842066742, 0.8782859210333709, 0.052697155262002256, 0.9253901541250579, 0.0462695077062529, 0.953663801879564, 0.9737791569940101, 0.6425784184628692, 0.03530650650894886, 0.021183903905369315, 0.10591951952684657, 0.19065513514832383, 0.9241716128050916, 0.2774528864687795, 0.7213775048188267, 0.11773154037333645, 0.8535536677066894, 0.05825401883271822, 0.9029372919071325, 0.02912700941635911, 0.03767309415169612, 0.9418273537924029, 0.05251970645899056, 0.772789966468004, 0.03001126083370889, 0.14255348896011724, 0.007148349120280708, 0.9078403382756499, 0.03574174560140354, 0.04289009472168425, 0.34287797433950395, 0.34922756645690217, 0.09524388176097331, 0.06349592117398221, 0.14604061870015908, 0.9395975287513404, 0.03613836649043617, 0.018069183245218084, 0.033355349626281866, 0.8422225780636171, 0.07504953665913419, 0.0250165122197114, 0.016677674813140933, 0.9084747613776205, 0.02930563746379421, 0.02930563746379421, 0.035059651563967405, 0.9466105922271199, 0.941460345815943, 0.026277248377627217, 0.026277248377627217, 0.21021798702101774, 0.7357629545735621, 0.154618898301546, 0.618475593206184, 0.04598607963764106, 0.04598607963764106, 0.9197215927528212, 0.039271787014218996, 0.013090595671406333, 0.026181191342812667, 0.7330733575987546, 0.18981363723539182, 0.3947086719879271, 0.18527141746372086, 0.4188745090484124, 0.5131247476561287, 0.12236051674876915, 0.07499515542666496, 0.1539374242968386, 0.1342018570792952, 0.9148003729492106, 0.211285792960952, 0.079232172360357, 0.686678827123094, 0.8736717891849405, 0.04598272574657582, 0.04598272574657582, 0.9167080412025611, 0.047010668779618514, 0.023505334389809257, 0.2565620002018618, 0.7183736005652132, 0.1867202854808173, 0.07002010705530648, 0.6068409278126562, 0.1167001784255108, 0.1583018532308298, 0.8442765505644255, 0.9857987203084391, 0.014098342431849308, 0.9445889429339036, 0.042295027295547925, 0.1744104162220354, 0.24417458271084957, 0.2790566659552567, 0.18138683287091684, 0.1255754996798655, 0.9934020825308869, 0.40680361221309913, 0.36365777455413406, 0.043145837658965056, 0.1417648951651709, 0.043145837658965056, 0.17281382594093087, 0.5662410467000714, 0.11030669740910481, 0.014707559654547309, 0.13972181671819942, 0.021255289201427958, 0.5685789861381979, 0.03719675610249893, 0.1434732021096387, 0.22318053661499357, 0.97758535901237, 0.021886239380873956, 0.06810480175808431, 0.214043662668265, 0.5740261862467106, 0.0875633165461084, 0.06810480175808431, 0.06591144413783141, 0.8815655653434951, 0.024716791551686778, 0.024716791551686778, 0.9383200129312357, 0.018036306039571664, 0.9739605261368698, 0.21418669487825753, 0.36606453306465836, 0.1012518921242672, 0.07788607086482092, 0.2375525161377038, 0.07587751462667851, 0.32747137891513883, 0.2595809710912686, 0.09584528163369917, 0.2396132040842479, 0.9787383598052273, 0.9546494461884122, 0.044314186499365874, 0.849355241237846, 0.05169988424926019, 0.05169988424926019], \"Term\": [\"000\", \"000\", \"000\", \"000\", \"000\", \"1953\", \"1959\", \"1959\", \"1959\", \"1960\", \"1960\", \"1960\", \"1961\", \"1961\", \"1961\", \"1961\", \"1961\", \"36\", \"36\", \"36\", \"academic\", \"academic\", \"acres\", \"acres\", \"act\", \"act\", \"act\", \"act\", \"act\", \"adjustment\", \"adjustments\", \"administration\", \"administration\", \"administration\", \"advantages\", \"af\", \"af\", \"af\", \"af\", \"agreement\", \"agreement\", \"agreement\", \"aircraft\", \"aircraft\", \"allies\", \"allocation\", \"allocation\", \"allocation\", \"ambition\", \"ambition\", \"amended\", \"american\", \"american\", \"american\", \"american\", \"american\", \"anne\", \"anti\", \"anti\", \"anti\", \"approaches\", \"approaches\", \"area\", \"area\", \"area\", \"area\", \"area\", \"areas\", \"areas\", \"areas\", \"areas\", \"art\", \"art\", \"art\", \"art\", \"art\", \"artistic\", \"artistic\", \"artistic\", \"asked\", \"asked\", \"asked\", \"assessment\", \"authorized\", \"authorized\", \"available\", \"available\", \"available\", \"available\", \"available\", \"away\", \"away\", \"away\", \"away\", \"away\", \"baby\", \"ball\", \"ballet\", \"ballet\", \"ballet\", \"bankers\", \"baseball\", \"baseball\", \"benefits\", \"benefits\", \"benefits\", \"berlin\", \"berlin\", \"berlin\", \"best\", \"best\", \"best\", \"best\", \"best\", \"billion\", \"billion\", \"billion\", \"board\", \"board\", \"board\", \"board\", \"boat\", \"boat\", \"boat\", \"boats\", \"boats\", \"bonds\", \"bonds\", \"boy\", \"boy\", \"bridge\", \"bridge\", \"bridge\", \"brown\", \"brown\", \"brown\", \"business\", \"business\", \"business\", \"business\", \"business\", \"calendar\", \"came\", \"came\", \"came\", \"catholic\", \"catholic\", \"catholic\", \"catholic\", \"cattle\", \"cattle\", \"cattle\", \"chamber\", \"chamber\", \"chamber\", \"chemical\", \"chemical\", \"china\", \"china\", \"china\", \"cities\", \"cities\", \"city\", \"city\", \"city\", \"city\", \"city\", \"claim\", \"claim\", \"claim\", \"class\", \"class\", \"class\", \"clay\", \"clay\", \"clay\", \"clearing\", \"clever\", \"collective\", \"college\", \"college\", \"college\", \"college\", \"college\", \"come\", \"come\", \"come\", \"come\", \"come\", \"commodities\", \"communist\", \"communist\", \"communist\", \"communist\", \"company\", \"company\", \"company\", \"company\", \"company\", \"congo\", \"conservation\", \"cooling\", \"cooling\", \"cooling\", \"coordination\", \"corps\", \"corps\", \"corps\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"couldn\", \"couldn\", \"country\", \"country\", \"country\", \"country\", \"country\", \"county\", \"county\", \"county\", \"county\", \"court\", \"court\", \"court\", \"court\", \"creative\", \"creative\", \"creative\", \"crisis\", \"crisis\", \"cuba\", \"curriculum\", \"daily\", \"daily\", \"daily\", \"daily\", \"daughter\", \"day\", \"day\", \"day\", \"day\", \"day\", \"decline\", \"democrat\", \"department\", \"department\", \"department\", \"design\", \"design\", \"design\", \"design\", \"designer\", \"designer\", \"designer\", \"development\", \"development\", \"development\", \"development\", \"didn\", \"didn\", \"didn\", \"dimensions\", \"dimensions\", \"districts\", \"districts\", \"don\", \"don\", \"don\", \"don\", \"drill\", \"drill\", \"drill\", \"economic\", \"economic\", \"economic\", \"editor\", \"editor\", \"editor\", \"editorial\", \"editorial\", \"electronic\", \"employers\", \"engine\", \"engine\", \"engine\", \"engineer\", \"engineer\", \"engineer\", \"expenditures\", \"expenditures\", \"export\", \"exterior\", \"external\", \"eyes\", \"eyes\", \"eyes\", \"faculty\", \"faculty\", \"faculty\", \"fan\", \"farmers\", \"federal\", \"federal\", \"federal\", \"federal\", \"feed\", \"feed\", \"feed\", \"feed\", \"filing\", \"fiscal\", \"fiscal\", \"fishing\", \"fishing\", \"foreign\", \"foreign\", \"foreign\", \"foreign\", \"foreign\", \"forest\", \"forest\", \"forests\", \"formula\", \"formula\", \"foundation\", \"foundation\", \"foundation\", \"foundation\", \"freedom\", \"freedom\", \"freedom\", \"freedom\", \"gave\", \"gave\", \"gave\", \"gear\", \"gear\", \"gear\", \"general\", \"general\", \"general\", \"general\", \"general\", \"generations\", \"generations\", \"generations\", \"geneva\", \"george\", \"george\", \"god\", \"god\", \"god\", \"good\", \"good\", \"good\", \"good\", \"good\", \"got\", \"got\", \"got\", \"government\", \"government\", \"government\", \"government\", \"great\", \"great\", \"great\", \"great\", \"great\", \"gun\", \"gun\", \"hadn\", \"hair\", \"heating\", \"heating\", \"high\", \"high\", \"high\", \"high\", \"high\", \"hiring\", \"home\", \"home\", \"home\", \"home\", \"home\", \"house\", \"house\", \"house\", \"house\", \"house\", \"hughes\", \"hughes\", \"inch\", \"inch\", \"inch\", \"income\", \"income\", \"income\", \"independence\", \"independence\", \"independence\", \"india\", \"india\", \"instructions\", \"instructions\", \"interference\", \"interference\", \"interference\", \"interior\", \"interior\", \"interior\", \"interior\", \"island\", \"island\", \"island\", \"island\", \"island\", \"john\", \"john\", \"john\", \"john\", \"judging\", \"judging\", \"junior\", \"junior\", \"katanga\", \"kennedy\", \"kennedy\", \"kennedy\", \"kennedy\", \"kennedy\", \"khrushchev\", \"khrushchev\", \"knew\", \"knew\", \"knew\", \"knew\", \"knight\", \"knight\", \"knight\", \"know\", \"know\", \"know\", \"know\", \"labor\", \"labor\", \"labor\", \"labor\", \"labor\", \"laos\", \"laos\", \"large\", \"large\", \"large\", \"large\", \"large\", \"left\", \"left\", \"left\", \"left\", \"legislators\", \"level\", \"level\", \"level\", \"level\", \"level\", \"lever\", \"lever\", \"library\", \"library\", \"library\", \"listeners\", \"listeners\", \"lists\", \"little\", \"little\", \"little\", \"little\", \"little\", \"ll\", \"ll\", \"ll\", \"local\", \"local\", \"local\", \"local\", \"local\", \"looked\", \"looked\", \"lumber\", \"lumber\", \"lumber\", \"machine\", \"machine\", \"machine\", \"machine\", \"machinery\", \"machinery\", \"man\", \"man\", \"man\", \"man\", \"man\", \"marketing\", \"marketing\", \"marriage\", \"maybe\", \"measurement\", \"measurement\", \"medical\", \"medical\", \"medical\", \"medical\", \"members\", \"members\", \"members\", \"members\", \"men\", \"men\", \"men\", \"men\", \"men\", \"miles\", \"miles\", \"miles\", \"miles\", \"military\", \"military\", \"military\", \"million\", \"million\", \"million\", \"million\", \"monument\", \"monument\", \"mother\", \"motor\", \"motor\", \"motor\", \"motor\", \"motors\", \"motors\", \"motors\", \"movements\", \"movements\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mrs\", \"mrs\", \"municipalities\", \"music\", \"music\", \"music\", \"music\", \"musical\", \"musical\", \"national\", \"national\", \"national\", \"national\", \"national\", \"nations\", \"nations\", \"nations\", \"nations\", \"negotiations\", \"nice\", \"night\", \"night\", \"night\", \"night\", \"number\", \"number\", \"number\", \"number\", \"number\", \"occur\", \"officer\", \"officer\", \"officer\", \"oh\", \"old\", \"old\", \"old\", \"old\", \"old\", \"pale\", \"payment\", \"payment\", \"payments\", \"payments\", \"peace\", \"peace\", \"peace\", \"peace\", \"people\", \"people\", \"people\", \"people\", \"people\", \"philosopher\", \"pink\", \"place\", \"place\", \"place\", \"place\", \"place\", \"planners\", \"planning\", \"planning\", \"planning\", \"planning\", \"player\", \"pool\", \"pool\", \"pool\", \"precision\", \"precision\", \"premier\", \"president\", \"president\", \"president\", \"president\", \"president\", \"prestige\", \"procurement\", \"program\", \"program\", \"program\", \"program\", \"program\", \"promoting\", \"property\", \"property\", \"property\", \"public\", \"public\", \"public\", \"public\", \"public\", \"raises\", \"range\", \"range\", \"range\", \"range\", \"range\", \"recovery\", \"recreation\", \"recreation\", \"recreation\", \"report\", \"report\", \"report\", \"research\", \"research\", \"research\", \"research\", \"research\", \"revenues\", \"review\", \"review\", \"revolution\", \"revolution\", \"rhode\", \"rhode\", \"rhode\", \"rhode\", \"rhode\", \"right\", \"right\", \"right\", \"right\", \"right\", \"roads\", \"roads\", \"roads\", \"room\", \"room\", \"room\", \"room\", \"said\", \"said\", \"said\", \"said\", \"said\", \"sales\", \"sales\", \"sales\", \"sales\", \"sales\", \"santa\", \"school\", \"school\", \"school\", \"school\", \"school\", \"schools\", \"schools\", \"schools\", \"schools\", \"schools\", \"secretary\", \"secretary\", \"secretary\", \"secretary\", \"service\", \"service\", \"service\", \"service\", \"service\", \"shall\", \"shall\", \"shall\", \"shall\", \"shall\", \"shelter\", \"shooting\", \"shooting\", \"signals\", \"signals\", \"signs\", \"signs\", \"signs\", \"signs\", \"sir\", \"site\", \"site\", \"site\", \"sitting\", \"sizes\", \"small\", \"small\", \"small\", \"small\", \"small\", \"smiled\", \"son\", \"son\", \"son\", \"soviet\", \"soviet\", \"soviet\", \"soviet\", \"state\", \"state\", \"state\", \"state\", \"states\", \"states\", \"states\", \"states\", \"states\", \"stations\", \"stations\", \"stations\", \"stations\", \"stockholders\", \"stockholders\", \"stocks\", \"stopped\", \"system\", \"system\", \"system\", \"system\", \"system\", \"tangible\", \"tax\", \"tax\", \"teachers\", \"teachers\", \"term\", \"term\", \"term\", \"tests\", \"tests\", \"think\", \"think\", \"think\", \"think\", \"thought\", \"thought\", \"thought\", \"thought\", \"today\", \"today\", \"today\", \"today\", \"today\", \"told\", \"told\", \"told\", \"took\", \"took\", \"took\", \"took\", \"took\", \"towns\", \"towns\", \"towns\", \"treasury\", \"treasury\", \"trophy\", \"trust\", \"trust\", \"trust\", \"trust\", \"twentieth\", \"twentieth\", \"unions\", \"unions\", \"unions\", \"united\", \"united\", \"united\", \"united\", \"united\", \"university\", \"university\", \"university\", \"use\", \"use\", \"use\", \"use\", \"use\", \"va\", \"vacation\", \"vacation\", \"vacation\", \"vehicle\", \"vehicle\", \"vehicle\", \"vehicles\", \"vehicles\", \"vehicles\", \"vernon\", \"vernon\", \"volume\", \"volume\", \"volume\", \"volume\", \"volunteers\", \"volunteers\", \"walked\", \"wanted\", \"wanted\", \"wanted\", \"war\", \"war\", \"war\", \"war\", \"war\", \"wasn\", \"water\", \"water\", \"water\", \"water\", \"water\", \"way\", \"way\", \"way\", \"way\", \"way\", \"week\", \"week\", \"week\", \"week\", \"week\", \"went\", \"went\", \"west\", \"west\", \"west\", \"west\", \"west\", \"white\", \"white\", \"white\", \"white\", \"wildlife\", \"woman\", \"woman\", \"work\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"world\", \"yankees\", \"yards\", \"young\", \"young\", \"young\", \"young\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1786427936320368967507433283\", ldavis_el1786427936320368967507433283_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1786427936320368967507433283\", ldavis_el1786427936320368967507433283_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1786427936320368967507433283\", ldavis_el1786427936320368967507433283_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14f32dd",
   "metadata": {},
   "source": [
    "Q: What conclusions do you draw from the visualization above? Please address the principal component scatterplot and the salient terms graph.\n",
    "\n",
    "A: it shows that the 5 topics are segreggated. Topic 2 is mostly from PC1 while Topic 3 is from PC2. Also it shows that some words are very dominent in specific topis. For example, word \"said\" is mostly inside TOpic 2, while word \"state\" shows up frequently in Topic 5 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1adfcad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb6ab0aca1cb3b88d28e39c0cd72da93ec1cda217f19bc0f068025ef404b92a3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
